{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f102c006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Feature1  Feature2 Class\n",
      "0       2.5       2.4     A\n",
      "1       0.5       0.7     A\n",
      "2       2.2       2.9     B\n",
      "3       1.9       2.2     B\n",
      "4       3.1       3.0     A \n",
      "\n",
      "Centered Data:\n",
      "    Feature1  Feature2\n",
      "0      0.46      0.16\n",
      "1     -1.54     -1.54\n",
      "2      0.16      0.66\n",
      "3     -0.14     -0.04\n",
      "4      1.06      0.76 \n",
      "\n",
      "Covariance Matrix:\n",
      " [[0.938  0.8405]\n",
      " [0.8405 0.853 ]] \n",
      "\n",
      "Eigenvalues:\n",
      " [1.73707382 0.05392618]\n",
      "Eigenvectors:\n",
      " [[ 0.72474155 -0.68902082]\n",
      " [ 0.68902082  0.72474155]] \n",
      "\n",
      "Sorted Eigenvectors (Principal Components):\n",
      " [[ 0.72474155 -0.68902082]\n",
      " [ 0.68902082  0.72474155]] \n",
      "\n",
      "Data projected onto top 2 principal components:\n",
      "    PC1  PC2 Class\n",
      "0  NaN  NaN     A\n",
      "1  NaN  NaN     A\n",
      "2  NaN  NaN     B\n",
      "3  NaN  NaN     B\n",
      "4  NaN  NaN     A \n",
      "\n",
      "Projected new sample onto top 2 PCs: [0.15015575 0.21599364] \n",
      "\n",
      "Predicted class of new sample: B\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create dataset\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': [2.5, 0.5, 2.2, 1.9, 3.1],\n",
    "    'Feature2': [2.4, 0.7, 2.9, 2.2, 3.0],\n",
    "    'Class': ['A', 'A', 'B', 'B', 'A']\n",
    "})\n",
    "\n",
    "print(\"Original Data:\\n\", data, \"\\n\")\n",
    "\n",
    "# Step 2: Center the data (subtract the mean of each feature)\n",
    "features = data[['Feature1', 'Feature2']]\n",
    "mean_vec = features.mean()\n",
    "centered = features - mean_vec\n",
    "print(\"Centered Data:\\n\", centered, \"\\n\")\n",
    "\n",
    "# Step 3: Compute the covariance matrix\n",
    "cov_matrix = np.cov(centered.T)\n",
    "print(\"Covariance Matrix:\\n\", cov_matrix, \"\\n\")\n",
    "\n",
    "# Step 4: Find eigenvalues and eigenvectors\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "print(\"Eigenvalues:\\n\", eig_vals)\n",
    "print(\"Eigenvectors:\\n\", eig_vecs, \"\\n\")\n",
    "\n",
    "# Step 5: Sort eigenvectors by descending eigenvalues\n",
    "sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "eig_vals = eig_vals[sorted_indices]\n",
    "eig_vecs = eig_vecs[:, sorted_indices]\n",
    "print(\"Sorted Eigenvectors (Principal Components):\\n\", eig_vecs, \"\\n\")\n",
    "\n",
    "# -------- Make it GENERIC --------\n",
    "n = 2   # Number of principal components you want to keep (1 or 2 for this dataset)\n",
    "\n",
    "# Step 6: Project data onto top 'n' principal components\n",
    "pcs = eig_vecs[:, :n]                     # Select top-n eigenvectors\n",
    "projected = centered.dot(pcs)             # Project data\n",
    "projected_df = pd.DataFrame(projected, columns=[f'PC{i+1}' for i in range(n)])\n",
    "data = pd.concat([data, projected_df], axis=1)\n",
    "\n",
    "print(f\"Data projected onto top {n} principal components:\\n\", data[[*projected_df.columns, 'Class']], \"\\n\")\n",
    "\n",
    "# Step 7: Project a new sample onto the same PCs\n",
    "new_sample = np.array([2.0, 2.5])\n",
    "new_centered = new_sample - mean_vec\n",
    "new_proj = new_centered.dot(pcs)\n",
    "print(f\"Projected new sample onto top {n} PCs:\", new_proj, \"\\n\")\n",
    "\n",
    "# Step 8: Predict class using nearest neighbor (in nD space)\n",
    "if n == 1:\n",
    "    # For 1D case, just compare PC1 values\n",
    "    closest_idx = np.abs(data['PC1'] - new_proj[0]).idxmin()\n",
    "else:\n",
    "    # For multi-dimensional case, use Euclidean distance\n",
    "    distances = np.linalg.norm(projected - new_proj, axis=1)\n",
    "    closest_idx = np.argmin(distances)\n",
    "\n",
    "predicted_class = data.loc[closest_idx, 'Class']\n",
    "print(\"Predicted class of new sample:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f681e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      " [[0.61655556 0.61544444]\n",
      " [0.61544444 0.71655556]]\n",
      "\n",
      "Eigenvalues: [1.28402771 0.0490834 ]\n",
      "Eigenvectors:\n",
      " [[-0.6778734  -0.73517866]\n",
      " [-0.73517866  0.6778734 ]]\n",
      "\n",
      "Reduced Data (1D):\n",
      " [[-0.82797019]\n",
      " [ 1.77758033]\n",
      " [-0.99219749]\n",
      " [-0.27421042]\n",
      " [-1.67580142]\n",
      " [-0.9129491 ]\n",
      " [ 0.09910944]\n",
      " [ 1.14457216]\n",
      " [ 0.43804614]\n",
      " [ 1.22382056]]\n",
      "\n",
      "Original shape: (10, 2)\n",
      "Reduced shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create a small dataset\n",
    "data = np.array([\n",
    "    [2.5, 2.4],\n",
    "    [0.5, 0.7],\n",
    "    [2.2, 2.9],\n",
    "    [1.9, 2.2],\n",
    "    [3.1, 3.0],\n",
    "    [2.3, 2.7],\n",
    "    [2.0, 1.6],\n",
    "    [1.0, 1.1],\n",
    "    [1.5, 1.6],\n",
    "    [1.1, 0.9]\n",
    "])\n",
    "\n",
    "# Step 2: Standardize the data\n",
    "mean = np.mean(data, axis=0)\n",
    "data_centered = data - mean\n",
    "\n",
    "# Step 3: Compute covariance matrix\n",
    "cov_matrix = np.cov(data_centered.T)\n",
    "print(\"Covariance Matrix:\\n\", cov_matrix)\n",
    "\n",
    "# Step 4: Compute eigenvalues and eigenvectors\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Step 5: Sort by eigenvalue (descending order)\n",
    "sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "eig_vals = eig_vals[sorted_indices]\n",
    "eig_vecs = eig_vecs[:, sorted_indices]\n",
    "\n",
    "print(\"\\nEigenvalues:\", eig_vals)\n",
    "print(\"Eigenvectors:\\n\", eig_vecs)\n",
    "\n",
    "# Step 6: Choose top k components (let’s take k=1)\n",
    "k = 1\n",
    "W = eig_vecs[:, :k]\n",
    "\n",
    "# Step 7: Transform data to new subspace\n",
    "X_reduced = np.dot(data_centered, W)\n",
    "print(\"\\nReduced Data (1D):\\n\", X_reduced)\n",
    "\n",
    "print(\"\\nOriginal shape:\", data.shape)\n",
    "print(\"Reduced shape:\", X_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdef6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (10, 3)\n",
      "After PCA shape: (10, 2)\n",
      "\n",
      "Predictions for test points: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Create a sample dataset\n",
    "# -------------------------------\n",
    "# Each row = [Feature1, Feature2, Feature3], last column = Class label\n",
    "data = np.array([\n",
    "    [2.5, 2.4, 1.8, 0],  # Class 0\n",
    "    [0.5, 0.7, 0.3, 0],\n",
    "    [2.2, 2.9, 1.6, 0],\n",
    "    [1.9, 2.2, 1.4, 0],\n",
    "    [3.1, 3.0, 2.0, 0],\n",
    "    [2.3, 2.7, 1.5, 1],\n",
    "    [2.0, 1.6, 1.2, 1],\n",
    "    [1.0, 1.1, 0.6, 1],\n",
    "    [1.5, 1.6, 0.9, 1],\n",
    "    [1.1, 0.9, 0.5, 1]\n",
    "])\n",
    "\n",
    "X = data[:, :-1]   # features\n",
    "y = data[:, -1]    # labels\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 2: Standardize (mean normalization)\n",
    "# -----------------------------------\n",
    "mean = np.mean(X, axis=0)\n",
    "X_centered = X - mean\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 3: Compute PCA manually\n",
    "# -----------------------------------\n",
    "cov_matrix = np.cov(X_centered.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort by descending eigenvalues\n",
    "sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "eig_vals = eig_vals[sorted_indices]\n",
    "eig_vecs = eig_vecs[:, sorted_indices]\n",
    "\n",
    "# Choose top k principal components\n",
    "k = 2\n",
    "W = eig_vecs[:, :k]\n",
    "\n",
    "# Transform data\n",
    "X_pca = np.dot(X_centered, W)\n",
    "print(\"Original shape:\", X.shape)\n",
    "print(\"After PCA shape:\", X_pca.shape)\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 4: Define KNN (using Manhattan distance)\n",
    "# -----------------------------------\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "def knn_predict(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "        for i, x_train in enumerate(X_train):\n",
    "            dist = manhattan_distance(test_point, x_train)\n",
    "            distances.append((dist, y_train[i]))\n",
    "        distances.sort(key=lambda x: x[0])  # sort by distance\n",
    "        neighbors = [label for (_, label) in distances[:k]]\n",
    "        # majority vote\n",
    "        prediction = max(set(neighbors), key=neighbors.count)\n",
    "        predictions.append(prediction)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 5: Test data (also apply PCA)\n",
    "# -----------------------------------\n",
    "X_test = np.array([[1.8, 2.0, 1.0],\n",
    "                   [2.9, 3.1, 1.8]])\n",
    "X_test_centered = X_test - mean\n",
    "X_test_pca = np.dot(X_test_centered, W)\n",
    "\n",
    "# -----------------------------------\n",
    "# Step 6: Predict using KNN\n",
    "# -----------------------------------\n",
    "k_value = 3\n",
    "predictions = knn_predict(X_pca, y, X_test_pca, k_value)\n",
    "\n",
    "print(\"\\nPredictions for test points:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0089e7",
   "metadata": {},
   "source": [
    "## QUESTION NUMBER 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecb1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   Feature 1  Feature 2 Class\n",
      "1        2.5        2.4     A\n",
      "2        0.5        0.7     A\n",
      "3        2.2        2.9     B\n",
      "4        1.9        2.2     B\n",
      "5        3.1        3.0     A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data = feature1, feature2\n",
    "data = np.array([[2.5, 2.4],\n",
    "                 [0.5, 0.7],\n",
    "                 [2.2, 2.9],\n",
    "                 [1.9, 2.2],\n",
    "                 [3.1, 3.0]])\n",
    "\n",
    "classes = np.array(['A', 'A', 'B', 'B', 'A'])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Feature 1', 'Feature 2'],index=[1,2,3,4,5])\n",
    "\n",
    "df['Class'] = classes\n",
    "print(\"Original Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ba34f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of feature 1 -  2.04 \tMean of feature 2 -  2.2399999999999998\n",
      "\n",
      "Centered Data:\n",
      " [[ 0.46  0.16]\n",
      " [-1.54 -1.54]\n",
      " [ 0.16  0.66]\n",
      " [-0.14 -0.04]\n",
      " [ 1.06  0.76]]\n"
     ]
    }
   ],
   "source": [
    "#calculate mean of each feature\n",
    "meanF1 = np.mean(data[:, 0])\n",
    "meanF2 = np.mean(data[:, 1])\n",
    "print(\"Mean of feature 1 - \",meanF1,\"\\tMean of feature 2 - \", meanF2)\n",
    "\n",
    "# Center the data by subtracting the mean\n",
    "centered_data = data - np.array([meanF1, meanF2])\n",
    "print(\"\\nCentered Data:\\n\",centered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1894f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.938  0.8405]\n",
      " [0.8405 0.853 ]]\n"
     ]
    }
   ],
   "source": [
    "# covariance matrix\n",
    "cov_matrix = np.cov(centered_data, rowvar=False)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3ec11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st E.Value =  1.737073823262107 \t2nd E.Value =  0.05392617673789313\n",
      "1st E.Vector =  [0.72474155 0.68902082] \t2nd E.Vector =  [-0.68902082  0.72474155]\n"
     ]
    }
   ],
   "source": [
    "Eval,Evec = np.linalg.eig(cov_matrix)\n",
    "print(\"1st E.Value = \",Eval[0],\"\\t2nd E.Value = \",Eval[1])\n",
    "# print(Evec)\n",
    "print(\"1st E.Vector = \",Evec[:,0],\"\\t2nd E.Vector = \",Evec[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77e6f7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[1.73707382 0.05392618]\n",
      "[[ 0.72474155 -0.68902082]\n",
      " [ 0.68902082  0.72474155]]\n"
     ]
    }
   ],
   "source": [
    "# Sorting eigenvalues and eigenvectors\n",
    "sorted_indices = np.argsort(Eval)[::-1]\n",
    "sorted_Eval = Eval[sorted_indices]\n",
    "sorted_Evec = Evec[:, sorted_indices]  \n",
    "print(sorted_indices)\n",
    "print(sorted_Eval)\n",
    "print(sorted_Evec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71213886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1st Principle Component:\n",
      " [0.72474155 0.68902082]\n",
      "\n",
      "2nd Principle Component:\n",
      " [-0.68902082  0.72474155]\n"
     ]
    }
   ],
   "source": [
    "# principle components\n",
    "\n",
    "firstComponent = sorted_Evec[:, 0]\n",
    "secondComponent = sorted_Evec[:, 1]\n",
    "print(\"\\n1st Principle Component:\\n\",firstComponent)\n",
    "print(\"\\n2nd Principle Component:\\n\",secondComponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1 Values (projection onto first principal component):\n",
      "Sample 1: 0.4436\n",
      "Sample 2: -2.1772\n",
      "Sample 3: 0.5707\n",
      "Sample 4: -0.1290\n",
      "Sample 5: 1.2919\n",
      "\n",
      "Projection Results:\n",
      "   Sample  Original_F1  Original_F2  PC1_Value Class\n",
      "0       1          2.5          2.4   0.443624     A\n",
      "1       2          0.5          0.7  -2.177194     A\n",
      "2       3          2.2          2.9   0.570712     B\n",
      "3       4          1.9          2.2  -0.129025     B\n",
      "4       5          3.1          3.0   1.291882     A\n"
     ]
    }
   ],
   "source": [
    "# Project data onto PC1\n",
    "pc1_values = centered_data.dot(firstComponent)\n",
    "print(\"PC1 Values (projection onto first principal component):\")\n",
    "for i, val in enumerate(pc1_values):\n",
    "    print(f\"Sample {i+1}: {val:.4f}\")\n",
    "\n",
    "# Create DataFrame showing the projection\n",
    "projection_df = pd.DataFrame({\n",
    "    'Sample': range(1, 6),\n",
    "    'Original_F1': data[:, 0],\n",
    "    'Original_F2': data[:, 1],\n",
    "    'PC1_Value': pc1_values,\n",
    "    'Class': classes\n",
    "})\n",
    "print(\"\\nProjection Results:\")\n",
    "print(projection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D data shape: (5, 2)\n",
      "Reduced 1D data shape: (5,)\n",
      "Dimensionality Reduction: 2D → 1D:\n",
      "\n",
      "Sample 1: (2.5, 2.4) → 0.44362444280870694\n",
      "Sample 2: (0.5, 0.7) → -2.1771940447906886\n",
      "Sample 3: (2.2, 2.9) → 0.5707123885045612\n",
      "Sample 4: (1.9, 2.2) → -0.1290246493796061\n",
      "Sample 5: (3.1, 3.0) → 1.2918818628570272\n"
     ]
    }
   ],
   "source": [
    "print(\"Original 2D data shape:\", data.shape)\n",
    "print(\"Reduced 1D data shape:\", pc1_values.shape)\n",
    "print(\"Dimensionality Reduction: 2D → 1D:\\n\")\n",
    "for i in range(len(data)):\n",
    "    print(f\"Sample {i+1}: ({data[i,0]}, {data[i,1]}) → {pc1_values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d631d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample: [2.  2.5]\n",
      "New Zero-Centered sample [-0.04  0.26]\n",
      "New sample PC1 value: 0.1502\n",
      "\n",
      "Classification based on PC1:\n",
      "\n",
      "Nearest sample: Sample 4\n",
      "Sample  4 = [1.9 2.2]  of class  B\n",
      "Predicted class: B\n"
     ]
    }
   ],
   "source": [
    "# New sample\n",
    "new_sample = np.array([2.0, 2.5])\n",
    "print(f\"New sample: {new_sample}\")\n",
    "new_sample_centered = new_sample - np.array([meanF1, meanF2])\n",
    "print(\"New Zero-Centered sample\",new_sample_centered)\n",
    "\n",
    "# Project onto PC1\n",
    "new_sample_pc1 = new_sample_centered.dot(firstComponent)\n",
    "print(f\"New sample PC1 value: {new_sample_pc1:.4f}\")\n",
    "\n",
    "# Simple classification using nearest neighbor in PC1 space\n",
    "distances = np.abs(pc1_values - new_sample_pc1)\n",
    "nearest_idx = np.argmin(distances)\n",
    "predicted_class = classes[nearest_idx]\n",
    "\n",
    "print(\"\\nClassification based on PC1:\")\n",
    "# print(\"Distances to existing samples in PC1 space:\")\n",
    "# for i, dist in enumerate(distances):\n",
    "#     print(f\"  Sample {i+1} (Class {classes[i]}): {dist:.4f}\")\n",
    "\n",
    "print(f\"\\nNearest sample: Sample {nearest_idx + 1}\")\n",
    "print(\"Sample \",nearest_idx+1 ,\"=\", data[nearest_idx],\" of class \",predicted_class)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67025f2d",
   "metadata": {},
   "source": [
    "## Question Number 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32c66a",
   "metadata": {},
   "source": [
    "# PART A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e61be38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2d50f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (178, 13)\n",
      "Number of classes: 3\n",
      "Feature names: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Class names: ['class_0' 'class_1' 'class_2']\n",
      "Sample data:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "X = wine.data  # Features (13 chemical properties)\n",
    "y = wine.target  # Target classes (0, 1, 2)\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Number of classes:\", len(np.unique(y)))\n",
    "print(\"Feature names:\", wine.feature_names)\n",
    "print(\"Class names:\", wine.target_names)\n",
    "print(\"Sample data:\\n\")\n",
    "sample=pd.DataFrame(X,columns=wine.feature_names)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5432b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before standardization: \n",
      " [[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]]\n",
      "After: \n",
      " [[ 1.51861254 -0.5622498   0.23205254 -1.16959318  1.91390522  0.80899739\n",
      "   1.03481896 -0.65956311  1.22488398  0.25171685  0.36217728  1.84791957\n",
      "   1.01300893]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before standardization: \\n\",X[:1])\n",
    "standardizedData = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "print(\"After: \\n\",standardizedData[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef0cf8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sample before standardization: \n",
      " [1.3e+01 2.0e+00 2.5e+00 1.6e+01 1.0e+02 2.5e+00 2.0e+00 3.0e-01 2.0e+00\n",
      " 5.0e+00 1.0e+00 3.0e+00 1.0e+03]\n",
      "New Sample after standardization: \n",
      " [-7.63365990e-04 -3.01927486e-01  4.87926405e-01 -1.04947918e+00\n",
      "  1.81450206e-02  3.28297930e-01 -2.93857675e-02 -4.98406993e-01\n",
      "  7.16779586e-01 -2.51279393e-02  1.86683727e-01  5.48472176e-01\n",
      "  8.06016834e-01]\n"
     ]
    }
   ],
   "source": [
    "newSample= np.array([13.0, 2.0, 2.5, 16.0, 100.0, 2.5, 2.0, 0.3, 2.0, 5.0, 1.0, 3.0, 1000.0])\n",
    "standardizedNewSample = (newSample - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "print(\"New Sample before standardization: \\n\",newSample)\n",
    "print(\"New Sample after standardization: \\n\",standardizedNewSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "180abf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for test sample: 0\n",
      "Distance to closest point: 1.6284\n",
      "Closest point index: 37\n"
     ]
    }
   ],
   "source": [
    "distances = np.array([EuclideanDistance(standardizedNewSample, standardizedData[i]) for i in range(len(standardizedData))])\n",
    "\n",
    "# Find the closest point\n",
    "sorted_indices = np.argsort(distances)\n",
    "closest_point_index = sorted_indices[0]\n",
    "\n",
    "# Get the prediction\n",
    "pred = y[closest_point_index]\n",
    "print(\"Predicted class for test sample:\", pred)\n",
    "print(f\"Distance to closest point: {distances[closest_point_index]:.4f}\")\n",
    "print(f\"Closest point index: {closest_point_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4079b5a",
   "metadata": {},
   "source": [
    "# PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60fe2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centered Data:\n",
      " [[ 1.51861254 -0.5622498   0.23205254 -1.16959318  1.91390522  0.80899739\n",
      "   1.03481896 -0.65956311  1.22488398  0.25171685  0.36217728  1.84791957\n",
      "   1.01300893]]\n",
      "\n",
      "Covariance Matrix:\n",
      " [[ 1.00564972  0.09493026  0.21273976 -0.31198788  0.27232816  0.29073446\n",
      "   0.23815287 -0.15681042  0.13747022  0.549451   -0.07215255  0.07275191\n",
      "   0.64735687]]\n"
     ]
    }
   ],
   "source": [
    "x_Centered = standardizedData - np.mean(standardizedData, axis=0)\n",
    "cov_matrix = np.cov(x_Centered, rowvar=False)\n",
    "print(\"Centered Data:\\n\",x_Centered[:1])\n",
    "print(\"\\nCovariance Matrix:\\n\", cov_matrix[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d565739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 Evals =  [4.73243698 2.51108093 1.45424187 0.92416587]\n",
      "Top 4 Evecs = \n",
      " [[-0.1443294   0.48365155 -0.20738262  0.0178563 ]\n",
      " [ 0.24518758  0.22493093  0.08901289 -0.53689028]\n",
      " [ 0.00205106  0.31606881  0.6262239   0.21417556]\n",
      " [ 0.23932041 -0.0105905   0.61208035 -0.06085941]\n",
      " [-0.14199204  0.299634    0.13075693  0.35179658]\n",
      " [-0.39466085  0.06503951  0.14617896 -0.19806835]\n",
      " [-0.4229343  -0.00335981  0.1506819  -0.15229479]\n",
      " [ 0.2985331   0.02877949  0.17036816  0.20330102]\n",
      " [-0.31342949  0.03930172  0.14945431 -0.39905653]\n",
      " [ 0.0886167   0.52999567 -0.13730621 -0.06592568]\n",
      " [-0.29671456 -0.27923515  0.08522192  0.42777141]\n",
      " [-0.37616741 -0.16449619  0.16600459 -0.18412074]\n",
      " [-0.28675223  0.36490283 -0.12674592  0.23207086]]\n"
     ]
    }
   ],
   "source": [
    "Eval,Evec = np.linalg.eig(cov_matrix)\n",
    "# print(Evec)  \n",
    "sortedIndex=np.argsort(Eval)[::-1]\n",
    "sorted_eigenvalues = Eval[sortedIndex]\n",
    "sorted_eigenvectors = Evec[:, sortedIndex]\n",
    "\n",
    "print(\"Top 4 Evals = \", sorted_eigenvalues[:4])\n",
    "print(\"Top 4 Evecs = \\n\", sorted_eigenvectors[:,:4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8852eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (178, 13)\n",
      "PCA matrix shape: (13, 4)\n",
      "\n",
      "Top 4 Samples in 4D PCA space:\n",
      " [[-3.31675081  1.44346263 -0.16573904  0.21563119]\n",
      " [-2.20946492 -0.33339289 -2.02645737  0.29135832]\n",
      " [-2.51674015  1.0311513   0.98281867 -0.72490231]\n",
      " [-3.75706561  2.75637191 -0.17619184 -0.56798331]]\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "PrincipleComponents = sorted_eigenvectors[:, :n]\n",
    "DataPCA4D = np.dot(x_Centered, PrincipleComponents)\n",
    "print(\"original data shape:\", standardizedData.shape)\n",
    "print(\"PCA matrix shape:\", PrincipleComponents.shape)\n",
    "print(\"\\nTop 4 Samples in 4D PCA space:\\n\", DataPCA4D[:4])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c92cc13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New sample in 4D PCA space:\n",
      " [-1.31230811  0.27621539 -0.28713416  0.05651436]\n"
     ]
    }
   ],
   "source": [
    "#transformation of new sample\n",
    "transformedSampleCentered = standardizedNewSample - np.mean(standardizedData, axis=0)\n",
    "transformedSamppleResult = np.dot(transformedSampleCentered, PrincipleComponents)\n",
    "print(\"\\nNew sample in 4D PCA space:\\n\", transformedSamppleResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "28e92acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class (4D PCA): 0\n",
      "Distance to closest point (4D): 0.6736\n",
      "Closest point index (4D): 26\n"
     ]
    }
   ],
   "source": [
    "#distance computation in 4D PCA space\n",
    "distances_4d = np.array([EuclideanDistance(transformedSamppleResult, DataPCA4D[i]) for i in range(len(DataPCA4D))])\n",
    "sorted_indices_pca = np.argsort(distances_4d)\n",
    "closest_point_index_pca = sorted_indices_pca[0]\n",
    "pred_pca_4d = y[closest_point_index_pca]\n",
    "\n",
    "print(f\"Predicted class (4D PCA): {pred_pca_4d}\")\n",
    "print(f\"Distance to closest point (4D): {distances_4d[closest_point_index_pca]:.4f}\")\n",
    "print(f\"Closest point index (4D): {closest_point_index_pca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0d597",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a25af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA transformed data shape: (178, 4)\n",
      "Transformed test sample shape: (1, 4)\n",
      "Predicted label: [0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "data = load_wine()\n",
    "X = pd.DataFrame(data['data'])\n",
    "y = data['target']\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(\"PCA transformed data shape:\", X_pca.shape)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_pca, y)\n",
    "\n",
    "test_sample = np.array([13.0, 2.0, 2.5, 16.0, 100.0, 2.5, 2.0, 0.3, 2.0, 5.0, 1.0, 3.0, 1000.0])\n",
    "\n",
    "test_sample_pca = pca.transform([test_sample])  \n",
    "print(\"Transformed test sample shape:\", test_sample_pca.shape)\n",
    "\n",
    "pred = knn.predict(test_sample_pca)\n",
    "print(\"Predicted label:\", pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
