{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647c11e2",
   "metadata": {},
   "source": [
    "## TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722b9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ab430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [1,2.1],[2,2.5],[1.5,2.3],[3,2.9],[2.2,2.6],[8,3.8],[7.5,3.6],[9,3.9],[7,3.5],[8.5,3.7],\n",
    "    [3.2,3.1],[2.8,2.8],[6,3.2],[6.5,3.3],[4,3.0],[5.5,3.4],[3.8,3.1],[4.2,3.2],[5,3.3],[6.8,3.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b862f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "505445e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Centroids:\n",
      " [[8.  3.8]\n",
      " [5.5 3.4]]\n",
      "\n",
      "\n",
      "Distances from Centroids:\n",
      " [[7.20347139 4.68401537]\n",
      " [6.13921819 3.6138622 ]\n",
      " [6.67083203 4.1484937 ]\n",
      " [5.08035432 2.54950976]\n",
      " [5.92283716 3.39558537]\n",
      " [0.         2.53179778]\n",
      " [0.53851648 2.00997512]\n",
      " [1.00498756 3.53553391]\n",
      " [1.04403065 1.50332964]\n",
      " [0.50990195 3.01496269]\n",
      " [4.85077313 2.3194827 ]\n",
      " [5.29528092 2.76586334]\n",
      " [2.0880613  0.53851648]\n",
      " [1.58113883 1.00498756]\n",
      " [4.07921561 1.55241747]\n",
      " [2.53179778 0.        ]\n",
      " [4.25793377 1.72626765]\n",
      " [3.84707681 1.31529464]\n",
      " [3.04138127 0.50990195]\n",
      " [1.26491106 1.3       ]]\n",
      "\n",
      "\n",
      "Cluster Assignments:\n",
      " [1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0]\n",
      "\n",
      "\n",
      "Final Cluster Assignments:\n",
      " [1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0]\n",
      "\n",
      "Final Centroids:\n",
      " [[7.2        3.53333333]\n",
      " [2.97272727 2.80909091]]\n"
     ]
    }
   ],
   "source": [
    "# You are given a dataset of 20 students with Study Hours and CGPA.\n",
    "# Your goal is to apply K-Means clustering (K = 2) and group students into 2 categories based on\n",
    "# performance patterns.\n",
    "# You must:\n",
    "# 1. Initialize centroids manually (random 2 points from dataset)\n",
    "\n",
    "k=2\n",
    "centroids = np.array([data[5], data[15]])\n",
    "print(\"Initial Centroids:\\n\", centroids)\n",
    "\n",
    "# 2. Calculate distance of each point from centroids (Euclidean distance)\n",
    "shape=data.shape[0]\n",
    "distances = np.zeros((shape, k)) # k # of clusters used for distance storage to each centroid\n",
    "for i in range(shape):\n",
    "    for j in range(k):\n",
    "        distances[i][j] = euclidean_distance(data[i], centroids[j])\n",
    "print(\"\\n\\nDistances from Centroids:\\n\", distances)\n",
    "\n",
    "# 3. Assign each point to the nearest cluster\n",
    "cluster_assignments = np.argmin(distances, axis=1)\n",
    "print(\"\\n\\nCluster Assignments:\\n\", cluster_assignments)\n",
    "\n",
    "\n",
    "# 4. Update centroids by averaging points in each cluster\n",
    "# 5. Repeat steps 2â€“4 until cluster assignments do not change (convergence)\n",
    "updatedCentroids = np.zeros((k, data.shape[1]))\n",
    "while True:\n",
    "    for j in range(k): # \n",
    "        ClusterPoint = data[cluster_assignments == j]   \n",
    "        if len(ClusterPoint) > 0:\n",
    "            updatedCentroids[j] = np.mean(ClusterPoint, axis=0)\n",
    "\n",
    "    distances = np.zeros((shape, k)) # Reset distances for new calculation\n",
    "    for i in range(shape):\n",
    "        for j in range(k):\n",
    "            distances[i][j] = euclidean_distance(data[i], updatedCentroids[j])\n",
    "    new_cluster_assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "    if np.array_equal(cluster_assignments, new_cluster_assignments):\n",
    "        break\n",
    "    cluster_assignments = new_cluster_assignments\n",
    "    centroids = updatedCentroids.copy()\n",
    "print(\"\\n\\nFinal Cluster Assignments:\\n\", cluster_assignments)\n",
    "print(\"\\nFinal Centroids:\\n\", updatedCentroids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c348a9",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "\"AI improves healthcare systems\",\n",
    "\"Machine learning models evolve\",\n",
    "\"Technology is changing education\",\n",
    "\"Deep learning achieves accuracy\",\n",
    "\"Computers process data fast\",\n",
    "\"Robots assist in industries\",\n",
    "\"Football players train daily\",\n",
    "\"Cricket match was exciting\",\n",
    "\"The team won the tournament\",\n",
    "\"Athletes need physical training\",\n",
    "\"Basketball is a popular sport\",\n",
    "\"Stadium crowd cheered loudly\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary Length:\n",
      " 47\n",
      "\n",
      "Vocabulary:\n",
      " {'athletes', 'cricket', 'match', 'players', 'process', 'models', 'sport', 'was', 'in', 'tournament', 'stadium', 'loudly', 'robots', 'ai', 'train', 'exciting', 'basketball', 'need', 'learning', 'crowd', 'systems', 'data', 'technology', 'industries', 'fast', 'computers', 'football', 'achieves', 'healthcare', 'evolve', 'improves', 'the', 'changing', 'popular', 'accuracy', 'daily', 'won', 'machine', 'education', 'assist', 'physical', 'deep', 'is', 'team', 'cheered', 'training', 'a'}\n",
      "\n",
      "\n",
      "Bag of Words Matrix:\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0\n",
      "  1 0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "\"AI improves healthcare systems\",\n",
    "\"Machine learning models evolve\",\n",
    "\"Technology is changing education\",\n",
    "\"Deep learning achieves accuracy\",\n",
    "\"Computers process data fast\",\n",
    "\"Robots assist in industries\",\n",
    "\"Football players train daily\",\n",
    "\"Cricket match was exciting\",\n",
    "\"The team won the tournament\",\n",
    "\"Athletes need physical training\",\n",
    "\"Basketball is a popular sport\",\n",
    "\"Stadium crowd cheered loudly\",\n",
    "]\n",
    "\n",
    "vocab = set()\n",
    "for doc in docs:\n",
    "    for word in doc.lower().split():\n",
    "        vocab.add(word)\n",
    "print(\"\\n\\nVocabulary Length:\\n\", len(vocab))\n",
    "print(\"\\nVocabulary:\\n\", vocab)\n",
    "\n",
    "def BagOfWords(docs,vocab):\n",
    "    bow_matrix = np.zeros((len(docs), len(vocab)), dtype=int)\n",
    "    for i, doc in enumerate(docs):\n",
    "        words = doc.lower().split()\n",
    "        for j, word in enumerate(vocab):\n",
    "            bow_matrix[i][j] = words.count(word)\n",
    "    return bow_matrix\n",
    "bow = BagOfWords(docs,vocab)\n",
    "print(\"\\n\\nBag of Words Matrix:\\n\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8187d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Final Document Cluster Assignments:\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "Document 0: Tech and AI Topics\n",
      "Document 1: Sports Topics\n",
      "Document 2: Tech and AI Topics\n",
      "Document 3: Sports Topics\n",
      "Document 4: Tech and AI Topics\n",
      "Document 5: Tech and AI Topics\n",
      "Document 6: Tech and AI Topics\n",
      "Document 7: Tech and AI Topics\n",
      "Document 8: Tech and AI Topics\n",
      "Document 9: Tech and AI Topics\n",
      "Document 10: Tech and AI Topics\n",
      "Document 11: Tech and AI Topics\n"
     ]
    }
   ],
   "source": [
    "k=2\n",
    "cluster1=\"Tech and AI Topics\"\n",
    "cluster2=\"Sports Topics\"\n",
    "\n",
    "\n",
    "# Compute similarity between documents (Euclidean distance on vectors)\n",
    "def euclidean_distance2(v1, v2):\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "\n",
    "centroids = np.array([bow[0], bow[1]])  # Initialize centroids with first Tech and first Sports doc\n",
    "shape=bow.shape[0]\n",
    "distances = np.zeros((shape, k))  # Distance storage\n",
    "\n",
    "# Calculating initial distances and assignments\n",
    "for i in range(shape):\n",
    "    for j in range(k):\n",
    "        distances[i][j] = euclidean_distance2(bow[i], centroids[j])\n",
    "cluster_assignments = np.argmin(distances, axis=1)\n",
    "updatedCentroids = np.zeros((k, bow.shape[1]))\n",
    "\n",
    "\n",
    "while True:\n",
    "    for j in range(k):  # For each cluster\n",
    "        ClusterPoint = bow[cluster_assignments == j]\n",
    "        if len(ClusterPoint) > 0:\n",
    "            updatedCentroids[j] = np.mean(ClusterPoint, axis=0)\n",
    "\n",
    "    distances = np.zeros((shape, k))  # Reset distances\n",
    "    for i in range(shape):\n",
    "        for j in range(k):\n",
    "            distances[i][j] = euclidean_distance2(bow[i], updatedCentroids[j])\n",
    "    new_cluster_assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "    if np.array_equal(cluster_assignments, new_cluster_assignments):\n",
    "        break\n",
    "    cluster_assignments = new_cluster_assignments\n",
    "    centroids = updatedCentroids.copy()\n",
    "\n",
    "\n",
    "print(\"\\n\\nFinal Document Cluster Assignments:\\n\", cluster_assignments)\n",
    "for i, assignment in enumerate(cluster_assignments):\n",
    "    topic = cluster1 if assignment == 0 else cluster2\n",
    "    print(f\"Document {i}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea49df0",
   "metadata": {},
   "source": [
    "## TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60663672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Data:\n",
      "    Age  Income  Gender City\n",
      "0    22      35    Male    A\n",
      "1    25      40  Female    B\n",
      "2    31      52    Male    A\n",
      "3    29      48  Female    C\n",
      "4    35      60    Male    B\n",
      "5    41      72  Female    A\n",
      "6    38      69    Male    C\n",
      "7    26      45  Female    A\n",
      "8    30      50    Male    B\n",
      "9    40      70  Female    C\n",
      "10   23      38  Female    B\n",
      "11   28      46    Male    A\n",
      "12   36      62  Female    B\n",
      "13   45      80    Male    C\n",
      "14   27      44    Male    A\n",
      "\n",
      "One-Hot Encoded Features:\n",
      "    Gender_Male  City_B  City_C\n",
      "0           1.0     0.0     0.0\n",
      "1           0.0     1.0     0.0\n",
      "2           1.0     0.0     0.0\n",
      "3           0.0     0.0     1.0\n",
      "4           1.0     1.0     0.0\n",
      "5           0.0     0.0     0.0\n",
      "6           1.0     0.0     1.0\n",
      "7           0.0     0.0     0.0\n",
      "8           1.0     1.0     0.0\n",
      "9           0.0     0.0     1.0\n",
      "10          0.0     1.0     0.0\n",
      "11          1.0     0.0     0.0\n",
      "12          0.0     1.0     0.0\n",
      "13          1.0     0.0     1.0\n",
      "14          1.0     0.0     0.0\n",
      "\n",
      "Scaled Numeric Features:\n",
      "    Age_scaled  Income_scaled\n",
      "0    -1.429999      -1.422481\n",
      "1    -0.989246      -1.049453\n",
      "2    -0.107740      -0.154185\n",
      "3    -0.401575      -0.452608\n",
      "4     0.479931       0.442660\n",
      "5     1.361437       1.337928\n",
      "6     0.920684       1.114111\n",
      "7    -0.842328      -0.676424\n",
      "8    -0.254657      -0.303396\n",
      "9     1.214519       1.188716\n",
      "10   -1.283081      -1.198664\n",
      "11   -0.548493      -0.601819\n",
      "12    0.626849       0.591871\n",
      "13    1.949108       1.934773\n",
      "14   -0.695410      -0.751030\n",
      "\n",
      "Final Data Used for K-Means:\n",
      "    Age_scaled  Income_scaled  Gender_Male  City_B  City_C\n",
      "0    -1.429999      -1.422481          1.0     0.0     0.0\n",
      "1    -0.989246      -1.049453          0.0     1.0     0.0\n",
      "2    -0.107740      -0.154185          1.0     0.0     0.0\n",
      "3    -0.401575      -0.452608          0.0     0.0     1.0\n",
      "4     0.479931       0.442660          1.0     1.0     0.0\n",
      "5     1.361437       1.337928          0.0     0.0     0.0\n",
      "6     0.920684       1.114111          1.0     0.0     1.0\n",
      "7    -0.842328      -0.676424          0.0     0.0     0.0\n",
      "8    -0.254657      -0.303396          1.0     1.0     0.0\n",
      "9     1.214519       1.188716          0.0     0.0     1.0\n",
      "10   -1.283081      -1.198664          0.0     1.0     0.0\n",
      "11   -0.548493      -0.601819          1.0     0.0     0.0\n",
      "12    0.626849       0.591871          0.0     1.0     0.0\n",
      "13    1.949108       1.934773          1.0     0.0     1.0\n",
      "14   -0.695410      -0.751030          1.0     0.0     0.0\n",
      "\n",
      "Cluster Assignments:\n",
      "    Age  Income  Gender City  Cluster\n",
      "0    22      35    Male    A        0\n",
      "1    25      40  Female    B        0\n",
      "2    31      52    Male    A        2\n",
      "3    29      48  Female    C        0\n",
      "4    35      60    Male    B        2\n",
      "5    41      72  Female    A        1\n",
      "6    38      69    Male    C        1\n",
      "7    26      45  Female    A        0\n",
      "8    30      50    Male    B        2\n",
      "9    40      70  Female    C        1\n",
      "10   23      38  Female    B        0\n",
      "11   28      46    Male    A        0\n",
      "12   36      62  Female    B        2\n",
      "13   45      80    Male    C        1\n",
      "14   27      44    Male    A        0\n",
      "\n",
      "Cluster Summary (Mean Age & Income):\n",
      "               Age     Income\n",
      "Cluster                      \n",
      "0        25.714286  42.285714\n",
      "1        41.000000  72.750000\n",
      "2        33.000000  56.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    " \n",
    "# 1. Load Dataset\n",
    "data = pd.DataFrame({\n",
    "    \"Age\":[22,25,31,29,35,41,38,26,30,40,23,28,36,45,27],\n",
    "    \"Income\":[35,40,52,48,60,72,69,45,50,70,38,46,62,80,44],\n",
    "    \"Gender\":[\"Male\",\"Female\",\"Male\",\"Female\",\"Male\",\"Female\",\"Male\",\"Female\",\"Male\",\"Female\",\"Female\",\"Male\",\"Female\",\"Male\",\"Male\"],\n",
    "    \"City\":[\"A\",\"B\",\"A\",\"C\",\"B\",\"A\",\"C\",\"A\",\"B\",\"C\",\"B\",\"A\",\"B\",\"C\",\"A\"]\n",
    "})\n",
    "\n",
    "print(\"\\nOriginal Data:\")\n",
    "print(data)\n",
    "\n",
    " \n",
    "# 2. One-Hot Encode Categorical Features\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "cat_features = encoder.fit_transform(data[[\"Gender\", \"City\"]])\n",
    "\n",
    "cat_df = pd.DataFrame(cat_features, columns=encoder.get_feature_names_out([\"Gender\", \"City\"]))\n",
    "print(\"\\nOne-Hot Encoded Features:\")\n",
    "print(cat_df)\n",
    "\n",
    " \n",
    "# 3. Scale Numeric Data\n",
    "scaler = StandardScaler()\n",
    "num_scaled = scaler.fit_transform(data[[\"Age\", \"Income\"]])\n",
    "num_df = pd.DataFrame(num_scaled, columns=[\"Age_scaled\", \"Income_scaled\"])\n",
    "\n",
    "print(\"\\nScaled Numeric Features:\")\n",
    "print(num_df)\n",
    "\n",
    " \n",
    "# 4. Combine Processed Data\n",
    "final_data = pd.concat([num_df, cat_df], axis=1)\n",
    "print(\"\\nFinal Data Used for K-Means:\")\n",
    "print(final_data)\n",
    "\n",
    " \n",
    "# 5. Apply K-Means (k = 3)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(final_data)\n",
    "data[\"Cluster\"] = clusters\n",
    "\n",
    "print(\"\\nCluster Assignments:\")\n",
    "print(data)\n",
    "\n",
    " \n",
    "# 6. Analyze Cluster Patterns\n",
    " \n",
    "cluster_summary = data.groupby(\"Cluster\")[[\"Age\", \"Income\"]].mean()\n",
    "print(\"\\nCluster Summary (Mean Age & Income):\")\n",
    "print(cluster_summary)\n",
    "\n",
    "\n",
    "#cluster 0 => young and med income\n",
    "#cluster 1 => v young and Low income\n",
    "#cluster 2 => older and high income"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
